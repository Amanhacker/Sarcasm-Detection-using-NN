{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mDATA\u001b[0m/                 \u001b[01;34mcode\u001b[0m/                          preprocess_bamman.sh\r\n",
      "README.md             crossfolds.sh                  \u001b[01;34mprogress\u001b[0m/\r\n",
      "SemEval_CUE_CNN.py    get_data.ipynb                 sarcasm_cnn.sh\r\n",
      "SemEval_data_set.py   get_word2vec_embeddings.ipynb  temp.txt\r\n",
      "\u001b[01;34maux\u001b[0m/                  init.sh                        train_CUE_CNN.py\r\n",
      "bamman_redux.txt      model_best.pth.tar             twitter_data_set.py\r\n",
      "bamman_redux_ids.txt  onefold.sh                     twitter_data_set.pyc\r\n",
      "checkpoint.pth.tar    param_sweep.py\r\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prahalarora/anaconda/envs/Ana2.7/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file code/my_utils/download_tweets.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python code/my_utils/download_tweets.py bamman_redux_ids.txt > bamman_redux.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Get Word Embeddings and User Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word embeddings:  word2vec.txt\n",
      "user embeddings:  usr2vec_400_master.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir DATA/txt\n",
    "cp bamman_redux.txt DATA/txt/bamman_redux.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Extract Vocabulary and Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]0;IPython: CSE291_NLP/CUE-CNN\u0007Preprocess Data\n",
      "Load Word Embeddings\n",
      "3534/14513 (24.35 %) words in vocabulary found no embedding\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "EMB_PATH_IN=\"DATA/embeddings/words.txt\"\n",
    "EMB_PATH_OUT=\"DATA/embeddings/filtered_embs.txt\"\n",
    "TXT_IN=\"DATA/txt/bamman_redux.txt\"\n",
    "TXT_OUT=\"DATA/txt/bamman_clean.txt\"\n",
    "python aux/preprocess_bamman.py -input   ${TXT_IN} \\\n",
    "                                -out_txt ${TXT_OUT} \\\n",
    "                                -word_vectors ${EMB_PATH_IN} \\\n",
    "                                -out_vectors  ${EMB_PATH_OUT} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]0;IPython: git_repo/Sarcasm-Detection-using-CNN\u0007Preprocess Data\n",
      "Load Word Embeddings\n",
      "3893/10958 (35.53 %) words in vocabulary found no embedding\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "EMB_PATH_IN=\"DATA/embeddings/words.txt\"\n",
    "EMB_PATH_OUT=\"DATA/embeddings/SemEval_filtered_embs.txt\"\n",
    "TXT_IN=\"DATA/txt/SemEval.txt\"\n",
    "TXT_OUT=\"DATA/txt/SemEval_clean.txt\"\n",
    "python aux/preprocess_bamman.py -input   ${TXT_IN} \\\n",
    "                                -out_txt ${TXT_OUT} \\\n",
    "                                -word_vectors ${EMB_PATH_IN} \\\n",
    "                                -out_vectors  ${EMB_PATH_OUT} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424063942164348928\tVato3forlife\t0\t@NonoB03 lmao hahah cochino she was a perfect Christain girl now you've turned her into a catholic nun! Hahahhahhaha orale ! Hahahha\n",
      "429350784850223104\tbesta90\t1\t@richard_neary hope so. Class player. #sarcasm\n",
      "522397523705872384\tUlsterBank_Help\t0\t@jamiehynds Hi, how many days were you advised the payment can take to credit? Can you confirm the fee you were charged? AS\n",
      "514625637974163456\tWynRichards\t0\t@vanbadham Arguably, it could be worse IMO\n",
      "481992089815625729\tdimples_misfit\t0\t‚Äú@ChristopherSoto: üò¥- dear bae, you are bae, there's no other bae, bae on my mind‚Äù I'm glad to know üòÇüôå\n",
      "532926621951721473\tUlsterBank_Help\t0\t@crustycraic I am sorry you have not yet received this. They need to help on the same number, as we have no access to the systems sadly. JP\n",
      "429681671685033985\tsloweddown\t0\t@JuliaHB1 Petitioning David Camaron To Recruit and pay for more Admiral Nurses . Petition by Jan Inman Clacton United Kingdom\n",
      "482530575748984832\tAdamEllis22\t0\t@benjaminryan too right! Just hope we received a just fee for him. As for the Bees- Alan Judge & Odubajo will be a tasty duo of wingers!\n",
      "439973448933462016\tB_Searcy4\t0\t@Sanchezioo I brought Greg some knee braces\n",
      "465725796947333120\tHeatherQ_ebooks\t0\t@MyCatEdwin \" but why would you deny me this pleasure\n",
      "\n",
      "\n",
      "424063942164348928\tVato3forlife\t0\t@user lmao hahah cochino she was a perfect christain girl now youve turned her into a catholic nun ! hahahhahhaha orale ! hahahha\n",
      "429350784850223104\tbesta90\t1\t@user hope so . class player .\n",
      "522397523705872384\tUlsterBank_Help\t0\t@user hi , how many days were you advised the payment can take to credit ? can you confirm the fee you were charged ? as\n",
      "514625637974163456\tWynRichards\t0\t@user arguably , it could be worse imo\n",
      "481992089815625729\tdimples_misfit\t0\t@user üò¥ - dear bae , you are bae , theres no other bae , bae on my mind ‚Äù im glad to know üòÇ üôå\n",
      "532926621951721473\tUlsterBank_Help\t0\t@user i am sorry you have not yet received this . they need to help on the same number , as we have no access to the systems sadly . jp\n",
      "429681671685033985\tsloweddown\t0\t@user petitioning david camaron to recruit and pay for more admiral nurses . petition by jan inman clacton united kingdom\n",
      "482530575748984832\tAdamEllis22\t0\t@user too right ! just hope we received a just fee for him . as for the bees - alan judge & odubajo will be a tasty duo of wingers !\n",
      "439973448933462016\tB_Searcy4\t0\t@user i brought greg some knee braces\n",
      "465725796947333120\tHeatherQ_ebooks\t0\t@user but why would you deny me this pleasure\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head DATA/txt/bamman_redux.txt\n",
    "echo \"\"\n",
    "echo \"\"\n",
    "head DATA/txt/bamman_clean.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1\t1\tSweet United Nations video. Just in time for Christmas. #imagine #NoReligion  http://t.co/fej2v3OUBR\n",
      "2\t2\t1\t@mrdahl87 We are rumored to have talked to Erv's agent... and the Angels asked about Ed Escobar... that's hardly nothing    ;)\n",
      "3\t3\t1\tHey there! Nice to see you Minnesota/ND Winter Weather \n",
      "4\t4\t0\t3 episodes left I'm dying over here\n",
      "5\t5\t1\tI can't breathe! was chosen as the most notable quote of the year in an annual list released by a Yale University librarian \n",
      "6\t6\t0\tYou're never too old for Footie Pajamas. http://t.co/ElzGqsX2yQ\n",
      "7\t7\t1\tNothing makes me happier then getting on the highway and seeing break lights light up like a Christmas tree.. \n",
      "8\t8\t0\t4:30 an opening my first beer now gonna be a long night/day\n",
      "9\t9\t0\t@Adam_Klug do you think you would support a guy who knocked out your daughter? Rice doesn't deserve support.\n",
      "10\t10\t0\t@samcguigan544 You are not allowed to open that until Christmas day!\n",
      "\n",
      "\n",
      "1\t1\t1\tsweet united nations video . just in time for christmas . #imagine #noreligion url\n",
      "2\t2\t1\t@user we are rumored to have talked to ervs agent ... and the angels asked about ed escobar ... thats hardly nothing ;)\n",
      "3\t3\t1\they there ! nice to see you minnesota / nd winter weather\n",
      "4\t4\t0\t3 episodes left im dying over here\n",
      "5\t5\t1\ti cant breathe ! was chosen as the most notable quote of the year in an annual list released by a yale university librarian\n",
      "6\t6\t0\tyoure never too old for footie pajamas . url\n",
      "7\t7\t1\tnothing makes me happier then getting on the highway and seeing break lights light up like a christmas tree ..\n",
      "8\t8\t0\tTIME an opening my first beer now gonna be a long night / day\n",
      "9\t9\t0\t@user do you think you would support a guy who knocked out your daughter ? rice doesnt deserve support .\n",
      "10\t10\t0\t@user you are not allowed to open that until christmas day !\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head DATA/txt/SemEval.txt\n",
    "echo \"\"\n",
    "echo \"\"\n",
    "head DATA/txt/SemEval_clean.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "[0.]  * 5 + list(np.random.uniform(0, 0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(0, 0, 5).reshape(5,).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0] * 5 for x in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.append([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 1, 2, 3, 4]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.append([0] * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
